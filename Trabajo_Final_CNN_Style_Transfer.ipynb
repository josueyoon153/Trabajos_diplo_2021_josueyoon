{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Trabajo_Final_CNN_Style_Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josueyoon153/Trabajos_diplo_2021_josueyoon/blob/main/Trabajo_Final_CNN_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHsa2t0SxZi"
      },
      "source": [
        "# Imagen para estilo\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
        "\n",
        "# Creamos el directorio para los archivos de salida\n",
        "!mkdir /content/output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIxH20o2eFoc"
      },
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IMAGEN BASE ELEGIDO PARA EL ULTIMO PUNTO\n",
        "from google.colab import files\n",
        "base_image = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6k2bqCANbaOR",
        "outputId": "aa1e3034-5091-424f-bb51-6491a9ca5be6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91749e0a-2953-4ce3-aa23-80b65eb49856\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91749e0a-2953-4ce3-aa23-80b65eb49856\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_1763.JPG to IMG_1763.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMAGEN ESTILO ELEGIDO PARA EL ULTIMO PUNTO\n",
        "style_reference_image = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "t7so8afNbiLy",
        "outputId": "70c296a8-4587-4575-c8d3-fe68e0c211b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-306ffbef-37f6-4126-9f7f-890d8480677a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-306ffbef-37f6-4126-9f7f-890d8480677a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Manifestacion-Berni-300-1024x734.jpeg to Manifestacion-Berni-300-1024x734.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
        "style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n",
        "result_prefix = Path(\"/content/output\")\n",
        "iterations = 100"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imagenes del\n",
        "base_image_path = Path(\"/content/IMG_1763.JPG\")\n",
        "style_reference_image_path = Path(\"/content/Manifestacion-Berni-300-1024x734.jpeg\")\n",
        "result_prefix = Path(\"/content/output\")\n",
        "iterations = 100"
      ],
      "metadata": {
        "id": "NH_SJEr3atjX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7E9Qa83ZNms",
        "outputId": "7ed5ea5d-0c69-4ace-8e45-e8e31b4f4397"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/775px-Neckarfront_Tübingen_Mai_2017.jpg')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "Respuesta: La idea central de este paper es separar el CONTENIDO y el ESTILO de una imagen utilizando una red convolucional. De esta forma poder manipular independientemente estos dos aspectos para luego poder obtener una nueva imagen combinando el contenido y el estilo de dos imagenes diferentes. Lo que el paper muestra detalladamente es que podemos regular el énfasis de la reconstrucción del estilo y del contenido. Sabiendo esto la variable \"style_weight\" hace referencia al peso que le vamos a estar dando al estilo y la variable \"content_weight\" hace referencia al peso que le vamos a estar danto al contenido de la imagen. Si el peso del estilo es más alto, intuitivamente podemos imaginarnos una imagen que predomine más el toque artístico donde captaríamos menos el contenido de la fotografía. Por el contrario si el peso del contenido es más alto identificaríamos claramente los rasgos de la fotografía y menos el toque artístico. Estos pesos van a estar ponderando la loss total que esta compuesta por la content_loss y la style_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "source": [
        "#peso original de la notebook\n",
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mucho mayor peso en el estilo\n",
        "total_variation_weight = 0.1\n",
        "style_weight = 10000\n",
        "content_weight = 1"
      ],
      "metadata": {
        "id": "tDNU8w0HrmH8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mucho mayor peso en el contenido\n",
        "total_variation_weight = 0.1\n",
        "style_weight = 1\n",
        "content_weight = 100"
      ],
      "metadata": {
        "id": "tXVI3iAAD9a7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
        "\n",
        "Ayuda: https://keras.io/applications/\n",
        "\n",
        "**Respuesta**: \n",
        "\n",
        "En las siguientes líneas de código lo que se define es un método que nos va a permitir cargar y preprocesar las imágenes de una forma rápida y eficiente utilizando la arquitectura VGG19 de preprocesamiento, una red de clasificación de imágenes previamente entrenada.\n",
        "Lo que se hace con np.expand_dims es expandir el shape del array indicando axis=0 lo que va a aumentar en una unidad la dimensión de la imagen cargada. Si vamos paso a paso en la segunda línea de código al pasar la imagen en array voy a tener el shape que tiene una imagen (a color en este caso que es [row size, col size, 3]). Sin embargo como KERAS trabaja con batch de imágenes necesitamos agregar una dimensión adicional lo cual la primera dimensión es utilizado por el número de samples (cant de imágenes) que tengo: (sample, row size, col size, 3)\n",
        "El preprocess_input es para adecuar la imagen a un formato que necesita el modelo. Esto es porque el modelo que usamos fue entrenado en distintos dataset por lo que el shape sigue siendo (sample, row size, col size, 3). \n",
        "El preprocess_input resta la media de los canales RGB de la dataset del imagenet. En otras palabras estamos normalizando los canales de los colores acorde a qué dataset fue usado en el entrenamiento de las redes anteriormente. \n",
        "\n",
        "Let's create methods that will allow us to load and preprocess our images easily. We perform the same preprocessing process as are expected according to the VGG training process. VGG networks are trained on image with each channel normalized by mean = [103.939, 116.779, 123.68]and with channels BGR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))#aca simplemente cargo la imagen que me interesa analizar con el tamaño ya definido\n",
        "    img = img_to_array(img)#transformo la img de forma matricial donde le shape es (400{img_nrows}, 517{img_ncols}, 3{rgb})\n",
        "    img = np.expand_dims(img, axis=0)#le agrego una dimension adicional donde ahora el shape es  (1, 400, 517, 3)\n",
        "    img = vgg19.preprocess_input(img)#The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.\n",
        "    return img"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "Respuesta: lo que hace esta celda es el camino inverso a lo que hace el preprocess_input(). Antes la idea era convertir las imágenes de RGB a BGR centrando a cero cada canal de color con respecto al dataset del imagenet. Esto se hacía restando la media de los canales RGB es decir, normalizar los canales de los colores acorde a qué dataset fue usado en el entrenamiento de las redes anteriormente. Sin embargo acá podemos observar que vuelve a hacer un reshape en 3 dimensiones y en lugar de restar la media hace una suma de las media. Aca estaríamos pasando de BGR a RGB. La relación es que es exactamente el camino inverso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Lbw02Uu--o"
      },
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdG59VRavHGB",
        "outputId": "c0e957ba-f080-4498-dce0-1c7f6851f131"
      },
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n",
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
        "\n",
        "Respuesta: Un estilo de una imagen es la correlación entre formas, colores y distribuciones de las mismas. Entonces podemos usar la red para extraer el estilo a través de las feature matrices. Para esto se utiliza la matriz de Gram que representa un estilo de una imagen computando la correlación entre diferentes features matrices las cuales ayuda a capturar el estilo de una imagen. (similitud entre filtros)\n",
        "\n",
        "Es importante saber lo que significa el producto punto entre dos vectores para poder entender mejor lo que hace una matriz de Gram: Teóricamente sabemos que el producto punto de dos vectores es la suma de los productos de las coordenadas repectivas. También lo entendemos como la longitud del vector \"a\" que va en la misma dirección que el vector b multiplicado por la longitud del vector \"b\". Intuitivamente muestra cuán similares son dos vectores entre ellos. Entonces imaginemos dos flattened feature vectors de un feature map de una convolucion. El producto punto de estos nos daría la información sobre la relación que tienen entre ellos. Mientras más chico sea el número del producto punto son más diferentes los features capurados y cuan más grande sea la misma habría más correlación entre los features. Esto nos da información sobre el estilo y la textura pero cero información sobre la estructura espacial debido a que ya se aplicó el flatten como un vector.\n",
        "\n",
        "Al computar el producto punto de todos los feature vectors (flattened de una feature map de una convolucional), tenemos como resultado una matriz de GRAM.\n",
        "\n",
        "- ¿Por qué se permutan las dimensiones de x?\n",
        "\n",
        "Las dimensiones de x se permutan porque lo que necesitamos hacer es que las filas sean los canales y las columnas las filas de cada canal que luego son flattened."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "source": [
        "def gram_matrix(x):\n",
        "    #hange height,width,depth to depth, height, width, it could be 2,1,0 too\n",
        "    ## We want each row to be a channel, and the columns to be flattened x,y locations\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))#aca estoy haciendo el producto punto del \n",
        "    #feature que es el vector flatten por la traspuesta de la misma\n",
        "    return gram"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "Rta:\n",
        "\n",
        "Content Loss: El objetivo del content loss es calcular cuan símiles o disímiles son los contenidos entre la imagen generada y la imagen de entrada que fue utilizada como content image.\n",
        "Capas más avanzadas de una convolucional contienen información de las macro estructuras. Se conoce que la CNN produce distintos features maps en capas mas avanzadas siendo estas activadas en presencia de diferentes objetos. Esto nos ayuda a deducir que las imágenes con los mismos contenidos deberían tambien tener activaciones similares en los higher layers.\n",
        "Siendo \"Combination\" la imagen output generada y \"base\" la imagen input de contenido, podemos ver que se eleva al cuadrado la resta entre los dos. El objetivo de esto es minimizar el content loss lo que significaría que la imagen generada sea muy parecida en contenido de la imagen input. Mientras más se parezca el contenido de la imagen output con la content image, el cuadrado de la resta va a ser menor.\n",
        "\n",
        "Style Loss: El concepto de este style loss es muy parecido al content loss solo que en lugar de tomar la distancia entre la imagen generada como output y la imagen input de contenido voy a tomar la imagen input que utilicé para captar el estilo. Entonces en este caso estamos tratando de saber cuan lejos/distante esta el estilo de nuestra imagen generada en comparación al style image.\n",
        "En el caso anterior comparamos los outputs de las capas intermedias de la convolución. Sin embargo no podemos hacer lo mismo para el style loss y necesitamos lo que es la gram matrix. Aca nosotros comparamos la diferencian entre las matrices de gram de una capa especifica para la imagen input de estilo y la imagen generada.\n",
        "En términos muy simples tendríamos:\n",
        "style loss = Generated image style - style image\n",
        "Para obtener el estilo tanto de la imagen generada como la imagen input de estilo necesitamos calcular la gram matrix de cada imagen. Por este motivo podemos ver que a \"S\" y \"C\" se le calcula la función gram matrix que definimos mas arriba.\n",
        "\n",
        "\n",
        "Total Variation Loss: Hemos dicho que el content loss calcula la diferencia que hay en el contenido de la imagen generada con el content input image. y el style loss calcula la diferencia de estilo entre la imagen generada con el style input image. Entonces con esto podemos calcular la total loss. simple mente significa content loss + style loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :] \n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pugBxEFRn8ZS",
        "outputId": "4c118259-a6c2-4f8f-ac4f-3b7ebf93c172"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"add_7:0\", shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbz4n1OhvV2K"
      },
      "source": [
        "\n",
        "#import tensorflow as tf\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "#with tf.GradientTape() as gtape:\n",
        "#  grads = gtape.gradient(loss, combination_image)\n",
        "#  grads = tape.gradient(loss, w)\n",
        "#grads = K.gradients(loss, combination_image)\n",
        "#grads = tf.GradientTape(loss, combination_image)\n",
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "eval_loss_and_grads: es para obtener el valor de la función de coste y los valores de los gradientes de cada imagen modificada que le pasamos como argumento.\n",
        "El método gradients de la celda anterior nos proporciona los gradientes de la imagen que minimizan la funcion de coste. Con esta información, después generamos una imagen modificada que se acerca a nuestro objetivo respecto a la imagen actual. Cada imagen modificada se va a pasar como argumento a eval_loss_and_grads() y así vamos obteniendo sucesivas imágenes que cada vez cumplen más con nuestro objetivo que es minimizar la función de coste es decir, que se parezcan a la imagen base pero con el estilo de la style image. En el punto 7 del trabajo se implementa esta iteración con un bucle donde se obtiene repetitivamente una imagen modificada/mejorada hacia nuestro objetivo.\n",
        "\n",
        "La funcion fmin_l_bfgs_b es un optimizador con una limitación donde requiere el loss y la gradiente de forma separada. Debido a que computar estos dos de forma independiente es extremadamente ineficiente en este caso se implementa un evaluator class que computa la loss y los valores de la grandiente de una sola vez.\n",
        "Este optimizador busca minimizar una función utilizando el algoritmo L-BFGS-B. Es una optimización que se realiza utilizando la derivada de segundo orden de una función objetivo. El algoritmo BFGS es uno de los algoritmos de segundo orden más utilizados para la optimización numérica y se usa comúnmente para adaptarse a los algoritmos de aprendizaje automático."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nav6s7s1n5U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n31YBwCVvhAI",
        "outputId": "fd22e582-734c-4f56-da08-6c438e8e2d9a"
      },
      "source": [
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 20288444000.0\n",
            "Image saved as /content/output/output_at_iteration_0.png\n",
            "Iteration 0 completed in 18s\n",
            "Start of iteration 1\n",
            "Current loss value: 9433432000.0\n",
            "Image saved as /content/output/output_at_iteration_1.png\n",
            "Iteration 1 completed in 6s\n",
            "Start of iteration 2\n",
            "Current loss value: 6965411300.0\n",
            "Image saved as /content/output/output_at_iteration_2.png\n",
            "Iteration 2 completed in 6s\n",
            "Start of iteration 3\n",
            "Current loss value: 5599468500.0\n",
            "Image saved as /content/output/output_at_iteration_3.png\n",
            "Iteration 3 completed in 6s\n",
            "Start of iteration 4\n",
            "Current loss value: 4859497500.0\n",
            "Image saved as /content/output/output_at_iteration_4.png\n",
            "Iteration 4 completed in 6s\n",
            "Start of iteration 5\n",
            "Current loss value: 4383176700.0\n",
            "Image saved as /content/output/output_at_iteration_5.png\n",
            "Iteration 5 completed in 6s\n",
            "Start of iteration 6\n",
            "Current loss value: 4023466200.0\n",
            "Image saved as /content/output/output_at_iteration_6.png\n",
            "Iteration 6 completed in 6s\n",
            "Start of iteration 7\n",
            "Current loss value: 3675673600.0\n",
            "Image saved as /content/output/output_at_iteration_7.png\n",
            "Iteration 7 completed in 6s\n",
            "Start of iteration 8\n",
            "Current loss value: 3464903400.0\n",
            "Image saved as /content/output/output_at_iteration_8.png\n",
            "Iteration 8 completed in 6s\n",
            "Start of iteration 9\n",
            "Current loss value: 3293153800.0\n",
            "Image saved as /content/output/output_at_iteration_9.png\n",
            "Iteration 9 completed in 6s\n",
            "Start of iteration 10\n",
            "Current loss value: 3129935000.0\n",
            "Image saved as /content/output/output_at_iteration_10.png\n",
            "Iteration 10 completed in 6s\n",
            "Start of iteration 11\n",
            "Current loss value: 2995266600.0\n",
            "Image saved as /content/output/output_at_iteration_11.png\n",
            "Iteration 11 completed in 6s\n",
            "Start of iteration 12\n",
            "Current loss value: 2892706800.0\n",
            "Image saved as /content/output/output_at_iteration_12.png\n",
            "Iteration 12 completed in 6s\n",
            "Start of iteration 13\n",
            "Current loss value: 2778181600.0\n",
            "Image saved as /content/output/output_at_iteration_13.png\n",
            "Iteration 13 completed in 6s\n",
            "Start of iteration 14\n",
            "Current loss value: 2658645800.0\n",
            "Image saved as /content/output/output_at_iteration_14.png\n",
            "Iteration 14 completed in 6s\n",
            "Start of iteration 15\n",
            "Current loss value: 2586507000.0\n",
            "Image saved as /content/output/output_at_iteration_15.png\n",
            "Iteration 15 completed in 6s\n",
            "Start of iteration 16\n",
            "Current loss value: 2515043300.0\n",
            "Image saved as /content/output/output_at_iteration_16.png\n",
            "Iteration 16 completed in 6s\n",
            "Start of iteration 17\n",
            "Current loss value: 2448680700.0\n",
            "Image saved as /content/output/output_at_iteration_17.png\n",
            "Iteration 17 completed in 7s\n",
            "Start of iteration 18\n",
            "Current loss value: 2391460000.0\n",
            "Image saved as /content/output/output_at_iteration_18.png\n",
            "Iteration 18 completed in 7s\n",
            "Start of iteration 19\n",
            "Current loss value: 2340835000.0\n",
            "Image saved as /content/output/output_at_iteration_19.png\n",
            "Iteration 19 completed in 7s\n",
            "Start of iteration 20\n",
            "Current loss value: 2289944600.0\n",
            "Image saved as /content/output/output_at_iteration_20.png\n",
            "Iteration 20 completed in 7s\n",
            "Start of iteration 21\n",
            "Current loss value: 2241474600.0\n",
            "Image saved as /content/output/output_at_iteration_21.png\n",
            "Iteration 21 completed in 7s\n",
            "Start of iteration 22\n",
            "Current loss value: 2192769000.0\n",
            "Image saved as /content/output/output_at_iteration_22.png\n",
            "Iteration 22 completed in 7s\n",
            "Start of iteration 23\n",
            "Current loss value: 2147594200.0\n",
            "Image saved as /content/output/output_at_iteration_23.png\n",
            "Iteration 23 completed in 7s\n",
            "Start of iteration 24\n",
            "Current loss value: 2111421800.0\n",
            "Image saved as /content/output/output_at_iteration_24.png\n",
            "Iteration 24 completed in 6s\n",
            "Start of iteration 25\n",
            "Current loss value: 2077681200.0\n",
            "Image saved as /content/output/output_at_iteration_25.png\n",
            "Iteration 25 completed in 6s\n",
            "Start of iteration 26\n",
            "Current loss value: 2043114100.0\n",
            "Image saved as /content/output/output_at_iteration_26.png\n",
            "Iteration 26 completed in 7s\n",
            "Start of iteration 27\n",
            "Current loss value: 2010236000.0\n",
            "Image saved as /content/output/output_at_iteration_27.png\n",
            "Iteration 27 completed in 7s\n",
            "Start of iteration 28\n",
            "Current loss value: 1981921200.0\n",
            "Image saved as /content/output/output_at_iteration_28.png\n",
            "Iteration 28 completed in 6s\n",
            "Start of iteration 29\n",
            "Current loss value: 1958218800.0\n",
            "Image saved as /content/output/output_at_iteration_29.png\n",
            "Iteration 29 completed in 7s\n",
            "Start of iteration 30\n",
            "Current loss value: 1936771300.0\n",
            "Image saved as /content/output/output_at_iteration_30.png\n",
            "Iteration 30 completed in 6s\n",
            "Start of iteration 31\n",
            "Current loss value: 1917910100.0\n",
            "Image saved as /content/output/output_at_iteration_31.png\n",
            "Iteration 31 completed in 6s\n",
            "Start of iteration 32\n",
            "Current loss value: 1895852400.0\n",
            "Image saved as /content/output/output_at_iteration_32.png\n",
            "Iteration 32 completed in 6s\n",
            "Start of iteration 33\n",
            "Current loss value: 1875558400.0\n",
            "Image saved as /content/output/output_at_iteration_33.png\n",
            "Iteration 33 completed in 6s\n",
            "Start of iteration 34\n",
            "Current loss value: 1854881900.0\n",
            "Image saved as /content/output/output_at_iteration_34.png\n",
            "Iteration 34 completed in 7s\n",
            "Start of iteration 35\n",
            "Current loss value: 1834092200.0\n",
            "Image saved as /content/output/output_at_iteration_35.png\n",
            "Iteration 35 completed in 7s\n",
            "Start of iteration 36\n",
            "Current loss value: 1814949100.0\n",
            "Image saved as /content/output/output_at_iteration_36.png\n",
            "Iteration 36 completed in 7s\n",
            "Start of iteration 37\n",
            "Current loss value: 1797646600.0\n",
            "Image saved as /content/output/output_at_iteration_37.png\n",
            "Iteration 37 completed in 7s\n",
            "Start of iteration 38\n",
            "Current loss value: 1777431000.0\n",
            "Image saved as /content/output/output_at_iteration_38.png\n",
            "Iteration 38 completed in 6s\n",
            "Start of iteration 39\n",
            "Current loss value: 1758864900.0\n",
            "Image saved as /content/output/output_at_iteration_39.png\n",
            "Iteration 39 completed in 7s\n",
            "Start of iteration 40\n",
            "Current loss value: 1743235000.0\n",
            "Image saved as /content/output/output_at_iteration_40.png\n",
            "Iteration 40 completed in 7s\n",
            "Start of iteration 41\n",
            "Current loss value: 1728677000.0\n",
            "Image saved as /content/output/output_at_iteration_41.png\n",
            "Iteration 41 completed in 6s\n",
            "Start of iteration 42\n",
            "Current loss value: 1713401700.0\n",
            "Image saved as /content/output/output_at_iteration_42.png\n",
            "Iteration 42 completed in 7s\n",
            "Start of iteration 43\n",
            "Current loss value: 1698812900.0\n",
            "Image saved as /content/output/output_at_iteration_43.png\n",
            "Iteration 43 completed in 6s\n",
            "Start of iteration 44\n",
            "Current loss value: 1685929300.0\n",
            "Image saved as /content/output/output_at_iteration_44.png\n",
            "Iteration 44 completed in 6s\n",
            "Start of iteration 45\n",
            "Current loss value: 1672900500.0\n",
            "Image saved as /content/output/output_at_iteration_45.png\n",
            "Iteration 45 completed in 7s\n",
            "Start of iteration 46\n",
            "Current loss value: 1660466200.0\n",
            "Image saved as /content/output/output_at_iteration_46.png\n",
            "Iteration 46 completed in 7s\n",
            "Start of iteration 47\n",
            "Current loss value: 1649206400.0\n",
            "Image saved as /content/output/output_at_iteration_47.png\n",
            "Iteration 47 completed in 7s\n",
            "Start of iteration 48\n",
            "Current loss value: 1638872300.0\n",
            "Image saved as /content/output/output_at_iteration_48.png\n",
            "Iteration 48 completed in 6s\n",
            "Start of iteration 49\n",
            "Current loss value: 1625495300.0\n",
            "Image saved as /content/output/output_at_iteration_49.png\n",
            "Iteration 49 completed in 7s\n",
            "Start of iteration 50\n",
            "Current loss value: 1614734200.0\n",
            "Image saved as /content/output/output_at_iteration_50.png\n",
            "Iteration 50 completed in 7s\n",
            "Start of iteration 51\n",
            "Current loss value: 1604896600.0\n",
            "Image saved as /content/output/output_at_iteration_51.png\n",
            "Iteration 51 completed in 6s\n",
            "Start of iteration 52\n",
            "Current loss value: 1594731000.0\n",
            "Image saved as /content/output/output_at_iteration_52.png\n",
            "Iteration 52 completed in 7s\n",
            "Start of iteration 53\n",
            "Current loss value: 1586213400.0\n",
            "Image saved as /content/output/output_at_iteration_53.png\n",
            "Iteration 53 completed in 7s\n",
            "Start of iteration 54\n",
            "Current loss value: 1576809700.0\n",
            "Image saved as /content/output/output_at_iteration_54.png\n",
            "Iteration 54 completed in 7s\n",
            "Start of iteration 55\n",
            "Current loss value: 1567092900.0\n",
            "Image saved as /content/output/output_at_iteration_55.png\n",
            "Iteration 55 completed in 7s\n",
            "Start of iteration 56\n",
            "Current loss value: 1558801200.0\n",
            "Image saved as /content/output/output_at_iteration_56.png\n",
            "Iteration 56 completed in 7s\n",
            "Start of iteration 57\n",
            "Current loss value: 1550163600.0\n",
            "Image saved as /content/output/output_at_iteration_57.png\n",
            "Iteration 57 completed in 7s\n",
            "Start of iteration 58\n",
            "Current loss value: 1542725800.0\n",
            "Image saved as /content/output/output_at_iteration_58.png\n",
            "Iteration 58 completed in 7s\n",
            "Start of iteration 59\n",
            "Current loss value: 1534683300.0\n",
            "Image saved as /content/output/output_at_iteration_59.png\n",
            "Iteration 59 completed in 7s\n",
            "Start of iteration 60\n",
            "Current loss value: 1526806700.0\n",
            "Image saved as /content/output/output_at_iteration_60.png\n",
            "Iteration 60 completed in 7s\n",
            "Start of iteration 61\n",
            "Current loss value: 1520228600.0\n",
            "Image saved as /content/output/output_at_iteration_61.png\n",
            "Iteration 61 completed in 7s\n",
            "Start of iteration 62\n",
            "Current loss value: 1512483700.0\n",
            "Image saved as /content/output/output_at_iteration_62.png\n",
            "Iteration 62 completed in 7s\n",
            "Start of iteration 63\n",
            "Current loss value: 1504254000.0\n",
            "Image saved as /content/output/output_at_iteration_63.png\n",
            "Iteration 63 completed in 7s\n",
            "Start of iteration 64\n",
            "Current loss value: 1497200800.0\n",
            "Image saved as /content/output/output_at_iteration_64.png\n",
            "Iteration 64 completed in 7s\n",
            "Start of iteration 65\n",
            "Current loss value: 1490358300.0\n",
            "Image saved as /content/output/output_at_iteration_65.png\n",
            "Iteration 65 completed in 7s\n",
            "Start of iteration 66\n",
            "Current loss value: 1483631600.0\n",
            "Image saved as /content/output/output_at_iteration_66.png\n",
            "Iteration 66 completed in 7s\n",
            "Start of iteration 67\n",
            "Current loss value: 1475408100.0\n",
            "Image saved as /content/output/output_at_iteration_67.png\n",
            "Iteration 67 completed in 7s\n",
            "Start of iteration 68\n",
            "Current loss value: 1467141000.0\n",
            "Image saved as /content/output/output_at_iteration_68.png\n",
            "Iteration 68 completed in 7s\n",
            "Start of iteration 69\n",
            "Current loss value: 1460919000.0\n",
            "Image saved as /content/output/output_at_iteration_69.png\n",
            "Iteration 69 completed in 7s\n",
            "Start of iteration 70\n",
            "Current loss value: 1454832400.0\n",
            "Image saved as /content/output/output_at_iteration_70.png\n",
            "Iteration 70 completed in 7s\n",
            "Start of iteration 71\n",
            "Current loss value: 1449440300.0\n",
            "Image saved as /content/output/output_at_iteration_71.png\n",
            "Iteration 71 completed in 7s\n",
            "Start of iteration 72\n",
            "Current loss value: 1444008400.0\n",
            "Image saved as /content/output/output_at_iteration_72.png\n",
            "Iteration 72 completed in 7s\n",
            "Start of iteration 73\n",
            "Current loss value: 1437556100.0\n",
            "Image saved as /content/output/output_at_iteration_73.png\n",
            "Iteration 73 completed in 7s\n",
            "Start of iteration 74\n",
            "Current loss value: 1431696300.0\n",
            "Image saved as /content/output/output_at_iteration_74.png\n",
            "Iteration 74 completed in 7s\n",
            "Start of iteration 75\n",
            "Current loss value: 1426442100.0\n",
            "Image saved as /content/output/output_at_iteration_75.png\n",
            "Iteration 75 completed in 7s\n",
            "Start of iteration 76\n",
            "Current loss value: 1421268700.0\n",
            "Image saved as /content/output/output_at_iteration_76.png\n",
            "Iteration 76 completed in 7s\n",
            "Start of iteration 77\n",
            "Current loss value: 1416248800.0\n",
            "Image saved as /content/output/output_at_iteration_77.png\n",
            "Iteration 77 completed in 7s\n",
            "Start of iteration 78\n",
            "Current loss value: 1411147800.0\n",
            "Image saved as /content/output/output_at_iteration_78.png\n",
            "Iteration 78 completed in 7s\n",
            "Start of iteration 79\n",
            "Current loss value: 1405297900.0\n",
            "Image saved as /content/output/output_at_iteration_79.png\n",
            "Iteration 79 completed in 7s\n",
            "Start of iteration 80\n",
            "Current loss value: 1400534400.0\n",
            "Image saved as /content/output/output_at_iteration_80.png\n",
            "Iteration 80 completed in 7s\n",
            "Start of iteration 81\n",
            "Current loss value: 1395576200.0\n",
            "Image saved as /content/output/output_at_iteration_81.png\n",
            "Iteration 81 completed in 7s\n",
            "Start of iteration 82\n",
            "Current loss value: 1391415800.0\n",
            "Image saved as /content/output/output_at_iteration_82.png\n",
            "Iteration 82 completed in 7s\n",
            "Start of iteration 83\n",
            "Current loss value: 1387315100.0\n",
            "Image saved as /content/output/output_at_iteration_83.png\n",
            "Iteration 83 completed in 7s\n",
            "Start of iteration 84\n",
            "Current loss value: 1383110500.0\n",
            "Image saved as /content/output/output_at_iteration_84.png\n",
            "Iteration 84 completed in 7s\n",
            "Start of iteration 85\n",
            "Current loss value: 1379164200.0\n",
            "Image saved as /content/output/output_at_iteration_85.png\n",
            "Iteration 85 completed in 7s\n",
            "Start of iteration 86\n",
            "Current loss value: 1375577900.0\n",
            "Image saved as /content/output/output_at_iteration_86.png\n",
            "Iteration 86 completed in 7s\n",
            "Start of iteration 87\n",
            "Current loss value: 1371964200.0\n",
            "Image saved as /content/output/output_at_iteration_87.png\n",
            "Iteration 87 completed in 7s\n",
            "Start of iteration 88\n",
            "Current loss value: 1367579900.0\n",
            "Image saved as /content/output/output_at_iteration_88.png\n",
            "Iteration 88 completed in 7s\n",
            "Start of iteration 89\n",
            "Current loss value: 1363528700.0\n",
            "Image saved as /content/output/output_at_iteration_89.png\n",
            "Iteration 89 completed in 7s\n",
            "Start of iteration 90\n",
            "Current loss value: 1358719200.0\n",
            "Image saved as /content/output/output_at_iteration_90.png\n",
            "Iteration 90 completed in 7s\n",
            "Start of iteration 91\n",
            "Current loss value: 1354005400.0\n",
            "Image saved as /content/output/output_at_iteration_91.png\n",
            "Iteration 91 completed in 7s\n",
            "Start of iteration 92\n",
            "Current loss value: 1348533000.0\n",
            "Image saved as /content/output/output_at_iteration_92.png\n",
            "Iteration 92 completed in 7s\n",
            "Start of iteration 93\n",
            "Current loss value: 1343943800.0\n",
            "Image saved as /content/output/output_at_iteration_93.png\n",
            "Iteration 93 completed in 7s\n",
            "Start of iteration 94\n",
            "Current loss value: 1340042500.0\n",
            "Image saved as /content/output/output_at_iteration_94.png\n",
            "Iteration 94 completed in 7s\n",
            "Start of iteration 95\n",
            "Current loss value: 1335452700.0\n",
            "Image saved as /content/output/output_at_iteration_95.png\n",
            "Iteration 95 completed in 7s\n",
            "Start of iteration 96\n",
            "Current loss value: 1331090000.0\n",
            "Image saved as /content/output/output_at_iteration_96.png\n",
            "Iteration 96 completed in 7s\n",
            "Start of iteration 97\n",
            "Current loss value: 1327581600.0\n",
            "Image saved as /content/output/output_at_iteration_97.png\n",
            "Iteration 97 completed in 7s\n",
            "Start of iteration 98\n",
            "Current loss value: 1323423400.0\n",
            "Image saved as /content/output/output_at_iteration_98.png\n",
            "Iteration 98 completed in 7s\n",
            "Start of iteration 99\n",
            "Current loss value: 1318860700.0\n",
            "Image saved as /content/output/output_at_iteration_99.png\n",
            "Iteration 99 completed in 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "Respuesta: Como default en la notebook tenemos content_weight=1 y style_weight=10 dándole un poco mas de peso al estilo para que el énfasis esté en el style transfer asi como se llama la metodología. Con estos pesos podemos observar que a medida que va iterando obtenemos como output imágenes que conserva el contenido pero que claramente tiene el estilo del style image. Lo que hacemos con estos pesos es influenciar la loss del contenido y de estilo para que se pueda ir jugando con el énfasis puesto en el contenido o en el estilo. Viendo las imágenes generadas con este peso podemos decir que tiene un ratio donde a simple vista el énfasis está distribuído \"equitativamente\" (sabiendo que en realidad estamos ponderando más el estilo que el contenido) ya que conserva bien el contenido y las formas del contenido tanto como el estilo que toma de la obra de Van Gogh. Quizas en las primeras no se nota mucho la transferencia del estilo pero ya en las ultimas iteraciones podemos ver claramente el traspaso del estilo.\n",
        "\n",
        "Luego se hicieron 2 pruebas mas: una que pondere exageradamente mas el estilo y otro el contenido.\n",
        "\n",
        "Para el primer caso mencionado con mayor peso en el estilo los parámetros utilizados fueron:\n",
        "\n",
        "- style_weight = 10000\n",
        "- content_weight = 1\n",
        "\n",
        "Con estos parámetros se observó claramente la distorsión de las formas de los elementos que se ven en la imagen original como por ejemplo las casas. Al tener un peso muy grande en minimizar la loss del estilo las líneas y las formas son bastante más invadidas por el estilo.\n",
        "\n",
        "y para el caso que se dió mayor importancia al contenido los parámetros fueron:\n",
        "\n",
        "- style_weight: 1\n",
        "- content_weight: 100\n",
        "\n",
        "Con estos parámetros se observó una clara diferencia con los casos anteriores. Aunque la iteracion iba avanzando, el estilo de la obra de Van Gogh no predominó en el output de la imagen. Las formas de las casas y de los árboles se vieron definitivamente más nítidos mas cercanos a la foto real. \n",
        "\n",
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta: Como content_image elegí una fotografía tomada por mí en el medio de la ruta cuando estuve viajando por el norte de nuestro país (Cafayate). \n",
        "Como style image elegí la obra \"Desocupados\" de Berni (Artista argentino) debido a que casi el 80% de la imagen está cubierta por rostros muy típico del estilo de Berni. Me dió curiosidad de si el algoritmo tomaría el rostro como un estilo como para plasmarlo en un paisaje."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t5_Xg9S5f4i-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}